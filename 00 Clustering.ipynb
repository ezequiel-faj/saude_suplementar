{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":45321,"status":"error","timestamp":1687873878546,"user":{"displayName":"Ezequiel Fajreldines dos Santos","userId":"00413739594708143752"},"user_tz":180},"id":"NlIqU_T6B0Wt","outputId":"9afeed91-3b8c-4dc3-8a6f-78456bfecfdc"},"outputs":[],"source":["from pathlib import Path\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","import gensim\n","from gensim.utils import simple_preprocess\n","from yellowbrick.cluster import KElbowVisualizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.cluster import KMeans\n","from random import choice\n","import scipy\n","\n","BASEDIR = Path.cwd()\n","\n","# Loads the raw database\n","df = pd.read_csv(BASEDIR / 'data.csv', index_col=0)\n","\n","nltk.download('stopwords')\n","stop_words = stopwords.words('portuguese')\n","\n","# preprocessing definitions\n","def sent_to_words(sentences):\n","    for sentence in sentences:\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n","\n","def remove_stopwords(texts):\n","    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n","\n","def make_bigrams(texts):\n","    return [bigram_mod[doc] for doc in texts]\n","\n","# preprocessing applications\n","df = df.dropna(subset=['inteiro_teor'])\n","df.inteiro_teor = df.inteiro_teor.apply(lambda x : x.lower())\n","df['processed_text'] = remove_stopwords(list(sent_to_words(df.inteiro_teor)))\n","\n","bigram = gensim.models.Phrases(df.processed_text, min_count=5, threshold=100) # higher threshold fewer phrases.\n","bigram_mod = gensim.models.phrases.Phraser(bigram)\n","\n","df.processed_text = make_bigrams(list(sent_to_words(df.processed_text)))\n","df.processed_text = df.processed_text.apply(lambda x : ' '.join(x))\n","\n","\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(df.processed_text)\n","X = scipy.sparse.csr_matrix.toarray(X)\n","\n","model = KMeans()\n","\n","# KElbowVisualizer helps finding the optimal number of clusters. The tuple k sets the minimal and maximium number to be tested.\n","visualizer = KElbowVisualizer(model, k=(10,40))\n","visualizer.fit(X)\n","\n","# We create a new instance of the model, using the elbow value defined by the KElbowVisualizer as the number of clusters\n","model = KMeans(n_clusters=visualizer.elbow_value_ , init='k-means++', max_iter=300, n_init=10, random_state=42)\n","\n","model.fit(X)\n","df['cluster_00'] = model.predict(X)\n","df.to_csv(BASEDIR/'cluster_00.csv')\n","\n","# we create a sample of each cluster\n","df_sample = pd.concat([dfp.sample(min(12, dfp.shape[0])) for i, dfp in df.groupby('cluster_00')])\n","## The resampling randonmizes the dataframe\n","df_sample.sample(frac=1).reset_index(drop=True)\n","df_sample.to_csv(BASEDIR/'sample_00.csv')\n","\n","# we assign random researchers to each decision\n","researchers = ['A', 'B', 'C', 'D', 'E']\n","df_sample['researcher'] = df_sample.cluster_00.apply(lambda x : choice(researchers))\n","df_sample.drop(['processed_text', 'arquivo', 'cluster_00'], axis=1).to_excel(BASEDIR/'classifications__00.excel')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTu97vCWufPRAt7VQc07jM","mount_file_id":"1qWP42S7zOkgm9dG9Hi3Qibfhopqqp5DO","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
